from one tree to a forest : a unified solution for structured web-data-extraction structured-data , in the form of entities and associated attributes , has been a rich web resource for search-engines and knowledge databases . to efficiently extract structured-data from enormous websites in various verticals (e.g. , books , restaurants) , much research effort has been attracted , but most existing approaches either require considerable human effort or rely on strong features that lack of flexibility . we consider an ambitious scenario -- can we build a system that (1) is general enough to handle any vertical without re-implementation and (2) requires only one labeled example site from each vertical for training to automatically deal with other sites in the same vertical ? in this paper , we propose a unified solution to demonstrate the feasibility of this scenario . specifically , we design a set of weak but general-features to characterize vertical-knowledge (including attribute-specific semantics and inter-attribute layout relationships) . such features can be adopted in various verticals without redesign ; meanwhile , they are weak enough to avoid overfitting of the learnt knowledge to seed sites . given a new unseen site , the learnt knowledge is first applied to identify page-level candidate attribute values , while inevitably involve false-positives . to remove noise , site-level-information of the new site is then exploited to boost up the true values . the site-level-information is derived in an unsupervised manner , without harm to the applicability of the solution . promising experimental performance on 80 websites in 8 distinct verticals demonstrated the feasibility and flexibility of the proposed solution .