adarank : a boosting-algorithm for information-retrieval in this paper we address the issue of learning-to-rank for document-retrieval . in the task , a model is automatically created with some training-data and then is utilized for ranking of documents . the goodness of a model is usually evaluated with performance-measures such as map (mean-average-precision) and ndcg (normalized-discounted-cumulative-gain) . ideally a learning-algorithm would train a ranking-model that could directly optimize the performance-measures with respect to the training-data . existing methods , however , are only able to train ranking-models by minimizing loss-functions loosely related to the performance-measures . for example , ranking-svm and rankboost train ranking-models by minimizing classification errors on instance pairs . to deal with the problem , we propose a novel learning-algorithm within the framework of boosting , which can minimize a loss-function directly defined on the performance-measures . our algorithm , referred to as adarank , repeatedly constructs ` weak rankers ' on the basis of reweighted training-data and finally linearly combines the weak rankers for making ranking-predictions . we prove that the training-process of adarank is exactly that of enhancing the performance-measure used . experimental-results on four benchmark datasets show that adarank significantly outperforms the baseline methods of bm25 , ranking-svm , and rankboost .