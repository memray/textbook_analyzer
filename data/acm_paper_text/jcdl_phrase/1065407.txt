downloading textual hidden-web content through keyword-queries an ever-increasing amount of information on the web today is available only through search-interfaces : the users have to type in a set of keywords in a search form in order to access the pages from certain web-sites . these pages are often referred to as the hidden-web or the deep-web . since there are no static-links to the hidden-web pages , search-engines can not discover and index such pages and thus do not return them in the results . however , according to recent studies , the content provided by many hidden-web sites is often of very high quality and can be extremely valuable to many users.in this paper , we study how we can build an effective hidden-web crawler that can autonomously discover and download pages from the hidden-web . since the only `` entry point '' to a hidden-web site is a query-interface , the main challenge that a hidden-web crawler has to face is how to automatically generate meaningful queries to issue to the site . here , we provide a theoretical-framework to investigate the query-generation problem for the hidden-web and we propose effective policies for generating queries automatically . our policies proceed iteratively , issuing a different query in every iteration . we experimentally evaluate the effectiveness of these policies on 4 real hidden-web sites and our results are very promising . for instance , in one experiment , one of our policies downloaded more than 90 \ % of a hidden-web site (that contains 14 million documents) after issuing fewer than 100 queries .