<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>Matrix decompositions</title> 
  <meta name="description" content="Matrix decompositions" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="previous" href="linear-algebra-review-1.html" /> 
  <link rel="up" href="linear-algebra-review-1.html" /> 
  <link rel="next" href="term-document-matrices-and-singular-value-decompositions-1.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html4541" href="term-document-matrices-and-singular-value-decompositions-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html4535" href="linear-algebra-review-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html4531" href="linear-algebra-review-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html4537" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html4539" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html4542" href="term-document-matrices-and-singular-value-decompositions-1.html">Term-document matrices and singular</a> 
  <b> Up:</b> 
  <a name="tex2html4536" href="linear-algebra-review-1.html">Linear algebra review</a> 
  <b> Previous:</b> 
  <a name="tex2html4532" href="linear-algebra-review-1.html">Linear algebra review</a> &nbsp; 
  <b> <a name="tex2html4538" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html4540" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h2><a name="SECTION002311000000000000000"></a> <a name="sec:matdecomp"></a> <a name="p:matdecomp"></a> <br /> Matrix decompositions </h2> In this section we examine ways in which a square matrix can be 
  <i>factored</i> into the product of matrices derived from its eigenvectors; we refer to this process as 
  <a name="28615"></a> 
  <i>matrix decomposition</i> . 
  <a name="p:pagematdecomp"></a> Matrix decompositions similar to the ones in this section will form the basis of our principal text-analysis technique in Section 
  <a href="low-rank-approximations-1.html#sec:lsi">18.3</a> , where we will look at decompositions of non-square term-document matrices. The square decompositions in this section are simpler and can be treated with sufficient mathematical rigor to help the reader understand how such decompositions work. The detailed mathematical derivation of the more complex decompositions in Section 
  <a href="term-document-matrices-and-singular-value-decompositions-1.html#sec:svd">18.2</a> are beyond the scope of this book. 
  <p> We begin by giving two theorems on the decomposition of a square matrix into the product of three matrices of a special form. The first of these, Theorem&nbsp;<a href="#thm:eigendecomp">18.1.1</a>, gives the basic factorization of a square real-valued matrix into three factors. The second, Theorem&nbsp;<a href="#thm:symmeigendecomp">18.1.1</a>, applies to square symmetric matrices and is the basis of the singular value decomposition described in Theorem&nbsp;<a href="term-document-matrices-and-singular-value-decompositions-1.html#thm:svd">18.2</a>. </p>
  <p> <b>Theorem.</b> <i>(Matrix diagonalization theorem)</i> <a name="thm:eigendecomp"></a>Let <img width="13" height="32" align="MIDDLE" border="0" src="img1679.png" alt="$S$" /> be a square real-valued 
   <!-- MATH
 $\lsinoterms\times \lsinoterms$
 --> <img width="56" height="32" align="MIDDLE" border="0" src="img1669.png" alt="$\lsinoterms\times \lsinoterms$" /> matrix with <img width="20" height="32" align="MIDDLE" border="0" src="img1673.png" alt="$\lsinoterms$" /> linearly independent eigenvectors. Then there exists an <a name="28626"></a> <i>eigen decomposition</i> <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
S=U\Lambda U^{-1},
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><a name="eqn:eigendecomp"></a><img width="91" height="26" border="0" src="img1701.png" alt="\begin{displaymath}
S=U\Lambda U^{-1},
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (223)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> where the columns of 
  <img width="17" height="32" align="MIDDLE" border="0" src="img1702.png" alt="$U$" /> are the eigenvectors of 
  <img width="13" height="32" align="MIDDLE" border="0" src="img1679.png" alt="$S$" /> and 
  <img width="17" height="32" align="MIDDLE" border="0" src="img1703.png" alt="$\Lambda$" /> is a diagonal matrix whose diagonal entries are the eigenvalues of 
  <img width="13" height="32" align="MIDDLE" border="0" src="img1679.png" alt="$S$" /> in decreasing order 
  <br /> 
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
\left(
    \begin{array}{cccc}
      \lambda_1 & & & \\
       & \lambda_2 & & \\
       & & \cdots & \\
       & & & \lambda_\lsinoterms
    \end{array}
    \right), \lambda_i\geq\lambda_{i+1}.
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><a name="eqn:diagonal"></a><img width="244" height="83" border="0" src="img1704.png" alt="\begin{displaymath}
\left(
\begin{array}{cccc}
\lambda_1 &amp; &amp; &amp; \\
&amp; \lambda_...
..._\lsinoterms
\end{array} \right), \lambda_i\geq\lambda_{i+1}.
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (224)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> If the eigenvalues are distinct, then this decomposition is unique. 
  <b>End theorem.</b> 
  <p> To understand how Theorem&nbsp;<a href="#thm:eigendecomp">18.1.1</a> works, we note that <img width="17" height="32" align="MIDDLE" border="0" src="img1702.png" alt="$U$" /> has the eigenvectors of <img width="13" height="32" align="MIDDLE" border="0" src="img1679.png" alt="$S$" /> as columns <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
U=\left(
    \vec{u_1}\
    \vec{u_2}
    \cdots
    \vec{u_\lsinoterms}
    \right).
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><a name="eqn:diagen"></a><img width="137" height="28" border="0" src="img1705.png" alt="\begin{displaymath}
U=\left(
\vec{u_1}\
\vec{u_2}
\cdots
\vec{u_\lsinoterms}
\right).
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (225)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> Then we have 
  <br /> 
  <div align="CENTER"> 
   <!-- MATH
 \begin{eqnarray}
SU &=& S\left(
    \vec{u_1}\
    \vec{u_2}
    \cdots
    \vec{u_\lsinoterms}
    \right) \\
   &=& \left(
    \lambda_1\vec{u_1}\
    \lambda_2\vec{u_2}
    \cdots
    \lambda_\lsinoterms\vec{u_\lsinoterms}
    \right) \\
  &=& \left(
    \vec{u_1}\
    \vec{u_2}
    \cdots
    \vec{u_\lsinoterms}
    \right)\left(
    \begin{array}{cccc}
      \lambda_1 & & & \\
       & \lambda_2 & & \\
       & & \cdots & \\
       & & & \lambda_\lsinoterms
    \end{array}
    \right).
\end{eqnarray}
 --> 
   <table align="CENTER" cellpadding="0" width="100%"> 
    <tbody>
     <tr valign="MIDDLE">
      <td nowrap="" align="RIGHT"><img width="26" height="32" align="MIDDLE" border="0" src="img1706.png" alt="$\displaystyle SU$" /></td> 
      <td align="CENTER" nowrap=""><img width="17" height="32" align="MIDDLE" border="0" src="img313.png" alt="$\textstyle =$" /></td> 
      <td align="LEFT" nowrap=""><img width="114" height="34" align="MIDDLE" border="0" src="img1707.png" alt="$\displaystyle S\left(
\vec{u_1}\
\vec{u_2}
\cdots
\vec{u_\lsinoterms}
\right)$" /></td> 
      <td width="10" align="RIGHT"> (226)</td>
     </tr> 
     <tr valign="MIDDLE">
      <td nowrap="" align="RIGHT">&nbsp;</td> 
      <td align="CENTER" nowrap=""><img width="17" height="32" align="MIDDLE" border="0" src="img313.png" alt="$\textstyle =$" /></td> 
      <td align="LEFT" nowrap=""><img width="158" height="34" align="MIDDLE" border="0" src="img1708.png" alt="$\displaystyle \left(
\lambda_1\vec{u_1}\
\lambda_2\vec{u_2}
\cdots
\lambda_\lsinoterms\vec{u_\lsinoterms}
\right)$" /></td> 
      <td width="10" align="RIGHT"> (227)</td>
     </tr> 
     <tr valign="MIDDLE">
      <td nowrap="" align="RIGHT">&nbsp;</td> 
      <td align="CENTER" nowrap=""><img width="17" height="32" align="MIDDLE" border="0" src="img313.png" alt="$\textstyle =$" /></td> 
      <td align="LEFT" nowrap=""><img width="281" height="94" align="MIDDLE" border="0" src="img1709.png" alt="$\displaystyle \left(
\vec{u_1}\
\vec{u_2}
\cdots
\vec{u_\lsinoterms}
\rig...
..._2 &amp; &amp; \\
&amp; &amp; \cdots &amp; \\
&amp; &amp; &amp; \lambda_\lsinoterms
\end{array} \right).$" /></td> 
      <td width="10" align="RIGHT"> (228)</td>
     </tr> 
    </tbody>
   </table>
  </div> 
  <br clear="ALL" />
  <p></p> Thus, we have 
  <img width="74" height="32" align="MIDDLE" border="0" src="img1710.png" alt="$SU=U\Lambda$" />, or 
  <!-- MATH
 $S=U\Lambda U^{-1}$
 --> 
  <img width="91" height="38" align="MIDDLE" border="0" src="img1711.png" alt="$S=U\Lambda U^{-1}$" />. 
  <p> We next state a closely related decomposition of a symmetric square matrix into the product of matrices derived from its eigenvectors. This will pave the way for the development of our main tool for text analysis, the singular value decomposition (Section <a href="term-document-matrices-and-singular-value-decompositions-1.html#sec:svd">18.2</a> ). </p>
  <p> <b>Theorem.</b> <i>(Symmetric diagonalization theorem)</i> <a name="thm:symmeigendecomp"></a>Let <img width="13" height="32" align="MIDDLE" border="0" src="img1679.png" alt="$S$" /> be a square, symmetric real-valued 
   <!-- MATH
 $\lsinoterms\times \lsinoterms$
 --> <img width="56" height="32" align="MIDDLE" border="0" src="img1669.png" alt="$\lsinoterms\times \lsinoterms$" /> matrix with <img width="20" height="32" align="MIDDLE" border="0" src="img1673.png" alt="$\lsinoterms$" /> linearly independent eigenvectors. Then there exists a <a name="28666"></a> <i>symmetric diagonal decomposition</i> <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
S=Q\Lambda Q^{T},
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><a name="eqn:symmeigendecomp"></a><img width="82" height="27" border="0" src="img1712.png" alt="\begin{displaymath}
S=Q\Lambda Q^{T},
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (229)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> where the columns of 
  <img width="17" height="32" align="MIDDLE" border="0" src="img146.png" alt="$Q$" /> are the orthogonal and normalized (unit length, real) eigenvectors of 
  <img width="13" height="32" align="MIDDLE" border="0" src="img1679.png" alt="$S$" />, and 
  <img width="17" height="32" align="MIDDLE" border="0" src="img1703.png" alt="$\Lambda$" /> is the diagonal matrix whose entries are the eigenvalues of 
  <img width="13" height="32" align="MIDDLE" border="0" src="img1679.png" alt="$S$" />. Further, all entries of 
  <img width="17" height="32" align="MIDDLE" border="0" src="img146.png" alt="$Q$" /> are real and we have 
  <img width="78" height="38" align="MIDDLE" border="0" src="img1713.png" alt="$Q^{-1}=Q^T$" />. 
  <b>End theorem.</b> 
  <p> We will build on this symmetric diagonal decomposition to build low-rank approximations to term-document matrices. </p>
  <p> <b>Exercises.</b> </p>
  <ul> 
   <li>What is the rank of the <img width="39" height="32" align="MIDDLE" border="0" src="img1714.png" alt="$3\times 3$" /> diagonal matrix below? <br /> 
    <div align="RIGHT"> 
     <!-- MATH
 \begin{equation}
\left(
  \begin{array}{ccc}
    1 & 1 & 0 \\
    0 & 1 & 1 \\
    1 & 2 & 1 \\
  \end{array}
\right)
\end{equation}
 --> 
     <table width="100%" align="CENTER"> 
      <tbody>
       <tr valign="MIDDLE">
        <td align="CENTER" nowrap=""><img width="91" height="64" border="0" src="img1715.png" alt="\begin{displaymath}
\left(
\begin{array}{ccc}
1 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; 1 \\
1 &amp; 2 &amp; 1 \\
\end{array}\right)
\end{displaymath}" /></td> 
        <td width="10" align="RIGHT"> (230)</td>
       </tr> 
      </tbody>
     </table> 
     <br clear="ALL" />
    </div><p></p> <p> </p></li> 
   <li>Show that <img width="44" height="31" align="MIDDLE" border="0" src="img1716.png" alt="$\lambda=2$" /> is an eigenvalue of <br /> 
    <div align="RIGHT"> 
     <!-- MATH
 \begin{equation}
\lsimatrix=\left(
      \begin{array}{cc}
        6 & -2 \\
        4 & 0 \\
      \end{array}
    \right).
\end{equation}
 --> 
     <table width="100%" align="CENTER"> 
      <tbody>
       <tr valign="MIDDLE">
        <td align="CENTER" nowrap=""><img width="124" height="45" border="0" src="img1717.png" alt="\begin{displaymath}
\lsimatrix=\left(
\begin{array}{cc}
6 &amp; -2 \\
4 &amp; 0 \\
\end{array} \right).
\end{displaymath}" /></td> 
        <td width="10" align="RIGHT"> (231)</td>
       </tr> 
      </tbody>
     </table> 
     <br clear="ALL" />
    </div><p></p> Find the corresponding eigenvector. <p> </p></li> 
   <li>Compute the unique eigen decomposition of the <img width="39" height="32" align="MIDDLE" border="0" src="img154.png" alt="$2\times 2$" /> matrix in (<a href="linear-algebra-review-1.html#eqn:examplematrix">222</a>). <p> </p></li> 
  </ul> 
  <p> </p>
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html4541" href="term-document-matrices-and-singular-value-decompositions-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html4535" href="linear-algebra-review-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html4531" href="linear-algebra-review-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html4537" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html4539" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html4542" href="term-document-matrices-and-singular-value-decompositions-1.html">Term-document matrices and singular</a> 
  <b> Up:</b> 
  <a name="tex2html4536" href="linear-algebra-review-1.html">Linear algebra review</a> 
  <b> Previous:</b> 
  <a name="tex2html4532" href="linear-algebra-review-1.html">Linear algebra review</a> &nbsp; 
  <b> <a name="tex2html4538" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html4540" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>   
 </body>
</html>