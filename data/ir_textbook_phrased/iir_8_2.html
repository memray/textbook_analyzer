standard test-collections here is a list of the most standard test-collections and evaluation series . we focus particularly on test-collections for ad-hoc-information-retrieval system-evaluation , but also mention a couple of similar test-collections for text-classification . the cranfield collection . this was the pioneering test-collection in allowing precise quantitative measures of information-retrieval effectiveness , but is nowadays too small for anything but the most elementary pilot experiments . collected in the united-kingdom starting in the late 1950s , it contains 1398 abstracts of aerodynamics journal-articles , a set of 225 queries , and exhaustive relevance-judgments of all (query , document) pairs . text-retrieval-conference (trec) . the u.s. national institute of standards and technology (nist) has run a large ir test bed evaluation series since 1992 . within this framework , there have been many tracks over a range of different test-collections , but the best known test-collections are the ones used for the trec ad-hoc track during the first 8 trec evaluations between 1992 and 1999 . in total , these test-collections comprise 6 cds containing 1.89 million documents (mainly , but not exclusively , newswire articles) and relevance-judgments for 450 information-needs , which are called topics and specified in detailed text passages . individual test-collections are defined over different subsets of this data . the early trecs each consisted of 50 information-needs , evaluated over different but overlapping sets of documents . trecs 6-8 provide 150 information-needs over about 528,000 newswire and foreign broadcast-information-service articles . this is probably the best subcollection to use in future work , because it is the largest and the topics are more consistent . because the test document-collections are so large , there are no exhaustive relevance-judgments . rather , nist assessors ' relevance-judgments are available only for the documents that were among the top returned for some system which was entered in the trec-evaluation for which the information-need was developed . in more recent years , nist has done evaluations on larger document-collections , including the 25 million page gov2 web-page-collection . from the beginning , the nist test document-collections were orders of magnitude larger than anything available to researchers previously and gov2 is now the largest web collection easily available for research purposes . nevertheless , the size of gov2 is still more than 2 orders of magnitude smaller than the current size of the document-collections indexed by the large web-search companies . nii test-collections for ir systems (ntcir) . the ntcir project has built various test-collections of similar sizes to the trec collections , focusing on east asian-language and cross-language-information-retrieval , where queries are made in one language over a document-collection containing documents in one or more other languages . see : http://research.nii.ac.jp/ntcir/data/data-en.html cross-language-evaluation-forum (clef) . this evaluation series has concentrated on european languages and cross-language-information-retrieval . see : http://www.clef-campaign.org/ and reuters-rcv1 . for text-classification , the most used test-collection has been the reuters-21578 collection of 21578 newswire articles ; see chapter 13 , page 13.6 . more recently , reuters released the much larger reuters-corpus volume 1 (rcv1) , consisting of 806,791 documents ; see chapter 4 , page 4.2 . its scale and rich annotation makes it a better basis for future-research . 20 newsgroups . this is another widely used text-classification collection , collected by ken lang . it consists of 1000 articles from each of 20 usenet newsgroups (the newsgroup name being regarded as the category) . after the removal of duplicate articles , as it is usually used , it contains 18941 articles .