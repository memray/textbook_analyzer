dynamic-indexing thus far , we have assumed that the document collection is static . this is fine for collections that change infrequently or never (e.g. , the bible or shakespeare) . but most collections are modified frequently with documents being added , deleted , and updated . this means that new terms need to be added to the dictionary , and postings lists need to be updated for existing terms . the simplest way to achieve this is to periodically reconstruct the index from scratch . this is a good solution if the number of changes over time is small and a delay in making new documents searchable is acceptable - and if enough resources are available to construct a new index while the old one is still available for querying . if there is a requirement that new documents be included quickly , one solution is to maintain two indexes : a large main index and a small auxiliary index that stores new documents . the auxiliary index is kept in memory . searches are run across both indexes and results merged . deletions are stored in an invalidation bit vector . we can then filter out deleted documents before returning the search result . documents are updated by deleting and reinserting them . each time the auxiliary index becomes too large , we merge it into the main index . the cost of this merging operation depends on how we store the index in the file-system . if we store each postings list as a separate file , then the merge simply consists of extending each postings list of the main index by the corresponding postings list of the auxiliary index . in this scheme , the reason for keeping the auxiliary index is to reduce the number of disk seeks required over time . updating each document separately requires up to disk seeks , where is the average size of the vocabulary of documents in the collection . with an auxiliary index , we only put additional load on the disk when we merge auxiliary and main indexes . unfortunately , the one-file-per-postings-list scheme is infeasible because most file-systems can not efficiently handle very-large numbers of files . the simplest alternative is to store the index as one large file , that is , as a concatenation of all postings lists . in reality , we often choose a compromise between the two extremes (section 4.7) . to simplify the discussion , we choose the simple option of storing the index as one large file here . in this scheme , we process each posting times because we touch it during each of merges where is the size of the auxiliary index and the total number of postings . thus , the overall time-complexity is . (we neglect the representation of terms here and consider only the docids . for the purpose of time-complexity , a postings list is simply a list of docids .) figure : logarithmic merging . each token (termid , docid) is initially added to in-memory index by lm ergea ddt oken . l ogarithmicm erge initializes and . we can do better than by introducing indexes , , , ... of size , , ... postings percolate up this sequence of indexes and are processed only once on each level . this scheme is called logarithmic merging (figure 4.7) . as before , up to postings are accumulated in an in-memory auxiliary index , which we call . when the limit is reached , the postings in are transferred to a new index that is created on disk . the next time is full , it is merged with to create an index of size . then is either stored as (if there is n't already an) or merged with into (if exists) ; and so on . we service search requests by querying in-memory and all currently valid indexes on disk and merging the results . readers familiar with the binomial heap-data structure will recognize its similarity with the structure of the inverted-indexes in logarithmic merging . overall index-construction time is because each posting is processed only once on each of the levels . we trade this efficiency gain for a slow down of query-processing ; we now need to merge results from indexes as opposed to just two (the main and auxiliary indexes) . as in the auxiliary index scheme , we still need to merge very-large indexes occasionally (which slows down the search-system during the merge) , but this happens less frequently and the indexes involved in a merge on average are smaller . having multiple-indexes complicates the maintenance of collection-wide statistics . for example , it affects the spelling-correction algorithm in section 3.3 (page) that selects the corrected alternative with the most hits . with multiple-indexes and an invalidation bit vector , the correct number of hits for a term is no longer a simple lookup . in fact , all aspects of an ir-system - index-maintenance , query-processing , distribution , and so on - are more complex in logarithmic merging . because of this complexity of dynamic-indexing , some large search-engines adopt a reconstruction-from-scratch strategy . they do not construct indexes dynamically . instead , a new index is built from scratch periodically . query-processing is then switched from the new index and the old index is deleted . exercises . for and , perform a step-by-step simulation of the algorithm in figure 4.7 . create a table that shows , for each point in time at which tokens have been processed (-rrb- , which of the three indexes are in use . the first three lines of the table are given below . 2 0 0 0 0 4 0 0 0 1 6 0 0 1 0