results snippets having chosen or ranked the documents matching a query , we wish to present a results list that will be informative to the user . in many cases the user will not want to examine all the returned documents and so we want to make the results list informative enough that the user can do a final ranking of the documents for themselves based on relevance to their information need.the standard way of doing this is to provide a snippet , a short summary of the document , which is designed so as to allow the user to decide its relevance . typically , the snippet consists of the document title and a short summary , which is automatically extracted . the question is how to design the summary so as to maximize its usefulness to the user . the two basic kinds of summaries are static , which are always the same regardless of the query , and dynamic (or query-dependent) , which are customized according to the user 's information-need as deduced from a query . dynamic summaries attempt to explain why a particular document was retrieved for the query at hand . a static-summary is generally comprised of either or both a subset of the document and metadata associated with the document . the simplest form of summary takes the first two sentences or 50 words of a document , or extracts particular zones of a document , such as the title and author . instead of zones of a document , the summary can instead use metadata associated with the document . this may be an alternative way to provide an author or date , or may include elements which are designed to give a summary , such as the description metadata which can appear in the meta element of a web html page . this summary is typically extracted and cached at indexing time , in such a way that it can be retrieved and presented quickly when displaying search results , whereas having to access the actual document-content might be a relatively expensive operation . there has been extensive work within natural-language-processing (nlp) on better ways to do text-summarization . most such work still aims only to choose sentences from the original document to present and concentrates on how to select good sentences . the models typically combine positional factors , favoring the first and last paragraphs of documents and the first and last sentences of paragraphs , with content factors , emphasizing sentences with key terms , which have low document-frequency in the collection as a whole , but high-frequency and good distribution across the particular document being returned . in sophisticated nlp approaches , the system synthesizes sentences for a summary , either by doing full text generation or by editing and perhaps combining sentences used in the document . for example , it might delete a relative-clause or replace a pronoun with the noun-phrase that it refers to . this last class of methods remains in the realm of research and is seldom used for search-results : it is easier , safer , and often even better to just use sentences from the original document . dynamic summaries display one or more `` windows '' on the document , aiming to present the pieces that have the most utility to the user in evaluating the document with respect to their information-need . usually these windows contain one or several of the query terms , and so are often referred to as keyword-in-context (-rrb- snippets , though sometimes they may still be pieces of the text such as the title that are selected for their query-independent information-value just as in the case of static summarization . dynamic summaries are generated in conjunction with scoring . if the query is found as a phrase , occurrences of the phrase in the document will be shown as the summary . if not , windows within the document that contain multiple query terms will be selected . commonly these windows may just stretch some number of words to the left and right of the query terms . this is a place where nlp-techniques can usefully be employed : users prefer snippets that read well because they contain complete phrases . dynamic summaries are generally regarded as greatly improving the usability of ir systems , but they present a complication for ir-system design . a dynamic-summary can not be precomputed , but , on the other hand , if a system has only a positional index , then it can not easily reconstruct the context surrounding search-engine hits in order to generate such a dynamic-summary . this is one reason for using static summaries . the standard solution to this in a world of large and cheap disk-drives is to locally cache all the documents at index time (notwithstanding that this approach raises various legal , information-security and control issues that are far from resolved) as shown in figure 7.5 (page) . then , a system can simply scan a document which is about to appear in a displayed results list to find snippets containing the query words . beyond simply access to the text , producing a good kwic snippet requires some care . given a variety of keyword occurrences in a document , the goal is to choose fragments which are : (i) maximally informative about the discussion of those terms in the document , (ii) self-contained enough to be easy to read , and (iii) short enough to fit within the normally strict constraints on the space available for summaries . generating snippets must be fast since the system is typically generating many snippets for each query that it handles . rather than caching an entire document , it is common to cache only a generous but fixed size prefix of the document , such as perhaps 10,000 characters . for most common , short documents , the entire document is thus cached , but huge amounts of local storage will not be wasted on potentially vast documents . summaries of documents whose length exceeds the prefix size will be based on material in the prefix only , which is in general a useful zone in which to look for a document summary anyway . if a document has been updated since it was last processed by a crawler and indexer , these changes will be neither in the cache nor in the index . in these circumstances , neither the index nor the summary will accurately reflect the current contents of the document , but it is the differences between the summary and the actual document-content that will be more glaringly obvious to the end-user .