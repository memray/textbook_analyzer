the text-classification problem in text-classification , we are given a description of a document , where is the document space ; and a fixed set of classes . classes are also called categories or labels . typically , the document space is some type of high-dimensional-space , and the classes are human defined for the needs of an application , as in the examples china and documents that talk about multicore computer chips above . we are given a training-set of labeled documents , where . for example : (111) using a learning-method or learning-algorithm , we then wish to learn a classifier or classification function that maps documents to classes : (112) this type of learning is called supervised-learning because a supervisor (the human who defines the classes and labels training-documents) serves as a teacher directing the learning-process . we denote the supervised-learning method by and write . the learning-method takes the training-set as input and returns the learned classification function . most names for learning-methods are also used for classifiers . we talk about the naive-bayes (nb) learning-method when we say that `` naive-bayes is robust , '' meaning that it can be applied to many different learning problems and is unlikely to produce classifiers that fail catastrophically . but when we say that `` naive-bayes had an error-rate of 20 % , '' we are describing an experiment in which a particular nb classifier (which was produced by the nb-learning method) had a 20 % error-rate in an application . figure 13.1 shows an example of text-classification from the reuters-rcv1 collection , introduced in section 4.2 , page 4.2 . there are six classes (uk , china , ... , sports) , each with three training-documents . we show a few mnemonic words for each document 's content . the training-set provides some typical examples for each class , so that we can learn the classification function . once we have learned , we can apply it to the test-set (or test-data) , for example , the new document first private chinese airline whose class is unknown . in figure 13.1 , the classification function assigns the new document to class china , which is the correct assignment . the classes in text-classification often have some interesting structure such as the hierarchy in figure 13.1 . there are two instances each of region categories , industry categories , and subject area categories . a hierarchy can be an important aid in solving a classification-problem ; see section 15.3.2 for further discussion . until then , we will make the assumption in the text-classification chapters that the classes form a set with no subset relationships between them . figure 13.1 : classes , training-set , and test-set in text-classification . definition eqn : gammadef stipulates that a document is a member of exactly one class . this is not the most appropriate model for the hierarchy in figure 13.1 . for instance , a document about the 2008 olympics should be a member of two classes : the china class and the sports class . this type of classification-problem is referred to as an any-of problem and we will return to it in section 14.5 (page) . for the time being , we only consider one-of problems where a document is a member of exactly one class . our goal in text-classification is high accuracy on test-data or new data - for example , the newswire articles that we will encounter tomorrow morning in the multicore chip example . it is easy to achieve high accuracy on the training-set (e.g. , we can simply memorize the labels) . but high accuracy on the training-set in general does not mean that the classifier will work well on new data in an application . when we use the training-set to learn a classifier for test-data , we make the assumption that training-data and test-data are similar or from the same distribution . we defer a precise definition of this notion to section 14.6 (page) .