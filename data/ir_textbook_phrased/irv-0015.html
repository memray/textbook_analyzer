probabilistic indexing in the past few years , a detailed quantitative-model for automatic-indexing based on some statistical assumptions about the distribution of words in text has been worked out by bookstein , swanson , and harter [29 , 30 , 31] . the difference between the terms word-type and word-token is crucial to the understanding of their model . a token instantiates a type , so that it is possible to refer to the occurrence of a word-type war ; then a particular occurrence at one point in the text of a document (or abstract) will be a word-token . hence ` the frequency of occurrence of word w in a document ' means the number of word-tokens occurring in that document corresponding to a unique word-type . the type/token qualification of a word will be dropped whenever the context makes it clear what is meant when i simply refer to a ` word ' . in their model they consider the difference in the distributional behaviour of words as a guide to whether a word should be assigned as an index term . their starting point has been the much earlier work by stone and rubinoff [32] , damerau [33] , and dennis [34] who showed that the statistical behaviour of ` speciality ' words was different from that of ` function ' words . they found that function-words were closely modelled by a poisson-distribution over all documents whereas specialty words did not follow a poisson-distribution . specifically , if one is looking at the distribution of a function-word w over a set of texts then the probability , f (n) , that a text will have n occurrences of the function-word w is given by [-rsb- in general the parameter x will vary from word to word , and for a given word should be proportional to the length of the text . we also interpret x as the mean number of occurrences of the w in the set of texts . the bookstein-swanson-harter model assumes that specialty words are ` content-bearing ' whereas function-words are not . what this means is that a word randomly distributed according to a poisson-distribution is not informative about the document in which it occurs . at the same time , the fact that a word does not follow a poisson-distribution is assumed to indicate that it conveys information as to what a document is about . this is not an unreasonable view : knowing that the specialty word war occurs in the collection one would expect it to occur only in the relatively few documents that are about war . on the other hand , one would expect a typical function-word such as for to be randomly distributed . the model also assumes that a document can be about a word to some degree . this implies that in general a document-collection can be broken up into subsets ; each subset being made up of documents that are about a given word to the same degree . the fundamental hypothesis made now is that a content-bearing word is a word that distinguishes more than one class of documents with respect to the extent to which the topic referred to by the word is treated in the documents in each class . it is precisely these words that are the candidates for index-terms . these content-bearing words can be mechanically detected by measuring the extent to which their distributions deviate from that expected under a poisson-process . in this model the status of one of these content-words within a subset of documents of the same ` aboutness ' is one of non-content-bearing , that is , within the given subset it does not discriminate between further subsets . harter [31] has identified two assumptions , based upon which the above ideas can be used to provide a method of automatic-indexing . the aim is to specify a rule that for any given document will assign it index-terms selected from the list of candidates . the assumptions are : (1) the probability that a document will be found relevant to a request for information on a subject is a function of the relative extent to which the topic is treated in the document . (2) the number of tokens in a document is a function * of the extent to which the subject referred to by the word is treated in the document . in these assumptions a ` topic ' is identified with the ` subject of the request ' and with the ` subject referred to by the word ' . also , only single word requests are considered , although bookstein and kraft [35] in a more recent paper have attempted an extension to multi-word requests . the indexing rule-based on these assumptions indexes a document with word w if-and-only-if the probability of the document being judged relevant to a request for information on w exceeds some cost-function . to calculate the required probability-of-relevance for a content-bearing word we need to postulate what its distribution would look like . we know that it can not be a single poisson-distribution , and that it is intrinsic to a content-bearing word that it will distinguish between subsets of documents differing in the extent to which they treat the topic specified by the word . by assumption (2) , within one of these subsets the distribution of a content-bearing can however be described by a poisson-process . therefore , if there are only two such subsets differing in the extent to which they are about a word w then the distribution of w can be described by a mixture of two poisson-distributions . specifically , with the same notation as before we have here p1 is the probability of a random document belonging to one of the subsets and x1 and x2 are the mean occurrences in the two classes . this expression shows why the model is sometimes called the 2-poisson-model . it is important to note that it describes the statistical behaviour of a content-bearing word over two classes which are ` about ' that word to different extents , these classes are not necessarily the relevant and non-relevant documents although by * although harter [31] uses ` function ' in his wording of this assumption , i think ` measure ' would have been more appropriate . assumption (1) we can calculate the probability of relevance for any document from one of these classes . it is the ratio that is used to make the decision whether to assign an index term w that occurs k times in a document . this ratio is in fact the probability that the particular document belongs to the class which treats w to an average extent of x1 given that it contains exactly k occurrences of w . this ratio is compared with some cost-function based on the cost a user is prepared to attach to errors the system might make in retrieval . the details of its specification can be found in the cited papers . finally , although tests have shown that this model assigns ` sensible ' index-terms , it has not been tested from the point-of-view of its effectiveness in retrieval . ultimately that will determine whether it is acceptable as a model for automatic-indexing .