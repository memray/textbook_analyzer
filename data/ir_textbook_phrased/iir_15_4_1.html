a simple example of machine-learned scoring in this section we generalize the methodology of section 6.1.2 (page) to machine-learning of the scoring-function . in section 6.1.2 we considered a case where we had to combine boolean indicators of relevance ; here we consider more general factors to further develop the notion of machine-learned relevance . in particular , the factors we now consider go beyond boolean-functions of query-term presence in document zones , as in section 6.1.2 . we develop the ideas in a setting where the scoring-function is a linear combination of two factors : (1) the vector-space cosine-similarity between query and document and (2) the minimum window width within which the query terms lie . as we noted in section 7.2.2 (page) , query-term proximity is often very indicative of a document being on topic , especially with longer documents and on the web . among other things , this quantity gives us an implementation of implicit phrases . thus we have one factor that depends on the statistics of query terms in the document as a bag-of-words , and another that depends on proximity weighting . we consider only two features in the development of the ideas because a two-feature exposition remains simple enough to visualize . the technique can be generalized to many more features . as in section 6.1.2 , we are provided with a set of training-examples , each of which is a pair consisting of a query and a document , together with a relevance-judgment for that document on that query that is either relevant or nonrelevant . for each such example we can compute the vector-space cosine-similarity , as well as the window width . the result is a training-set as shown in table 15.3 , which resembles figure 6.5 (page) from section 6.1.2 . table 15.3 : training-examples for machine-learned scoring . example docid query cosine score judgment 37 linux-operating-system 0.032 3 relevant 37 penguin logo 0.02 4 nonrelevant 238 operating-system 0.043 2 relevant 238 runtime-environment 0.004 2 nonrelevant 1741 kernel layer 0.022 3 relevant 2094 device-driver 0.03 2 relevant 3191 device-driver 0.027 5 nonrelevant here , the two features (cosine score denoted and window width) are real-valued predictors . if we once again quantify the judgment relevant as 1 and nonrelevant as 0 , we seek a scoring-function that combines the values of the features to generate a value that is (close to) 0 or 1 . we wish this function to be in agreement with our set of training-examples as far as possible . without loss of generality , a linear classifier will use a linear combination-of-features of the form (179) 6.1.2 179 15.3 15.7 a collection of training examples.each r denotes a training-example labeled relevant , while each n is a training-example labeled nonrelevant . in this setting , the function from equation 179 represents a plane `` hanging above '' figure 15.7 . ideally this plane (in the direction perpendicular to the page containing figure 15.7) assumes values close to 1 above the points marked r , and values close to 0 above the points marked n . since a plane is unlikely to assume only values close to 0 or 1 above the training sample points , we make use of thresholding : given any query and document for which we wish to determine relevance , we pick a value and if we declare the document to be relevant , else we declare the document to be nonrelevant . as we know from figure 14.8 (page) , all points that satisfy form a line (shown as a dashed line in figure 15.7) and we thus have a linear classifier that separates relevant from nonrelevant instances . geometrically , we can find the separating line as follows . consider the line passing through the plane whose height is above the page containing figure 15.7 . project this line down onto figure 15.7 ; this will be the dashed line in figure 15.7 . then , any subsequent query/document pair that falls below the dashed line in figure 15.7 is deemed nonrelevant ; above the dashed line , relevant . thus , the problem of making a binary relevant/nonrelevant judgment given training-examples as above turns into one of learning the dashed line in figure 15.7 separating relevant training-examples from the nonrelevant ones . being in the - plane , this line can be written as a linear equation involving and , with two parameters (slope and intercept) . the methods of linear-classification that we have already looked at in classificationsvm provide methods for choosing this line . provided we can build a sufficiently rich collection of training-samples , we can thus altogether avoid hand-tuning score functions as in section 7.2.3 (page) . the bottleneck of course is the ability to maintain a suitably representative set of training-examples , whose relevance-assessments must be made by experts .