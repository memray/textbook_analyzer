choosing a document unit the next phase is to determine what the document unit for indexing is . thus far we have assumed that documents are fixed units for the purposes of indexing . for example , we take each file in a folder as a document . but there are many cases in which you might want to do something different . a traditional unix (mbox-format) email file stores a sequence of email-messages (an email folder) in one file , but you might wish to regard each email-message as a separate document . many email-messages now contain attached documents , and you might then want to regard the email-message and each contained attachment as separate documents . if an email-message has an attached zip file , you might want to decode the zip file and regard each file it contains as a separate document . going in the opposite direction , various pieces of web software (such as latex2html) take things that you might regard as a single-document (e.g. , a powerpoint file or a latex document) and split them into separate html pages for each slide or subsection , stored as separate files . in these cases , you might want to combine multiple files into a single-document . more generally , for very-long-documents , the issue of indexing granularity arises . for a collection of books , it would usually be a bad idea to index an entire book as a document . a search for chinese toys might bring up a book that mentions china in the first chapter and toys in the last chapter , but this does not make it relevant to the query . instead , we may well wish to index each chapter or paragraph as a mini-document . matches are then more likely to be relevant , and since the documents are smaller it will be much easier for the user to find the relevant passages in the document . but why stop there ? we could treat individual sentences as mini-documents . it becomes clear that there is a precisionrecall tradeoff here . if the units get too small , we are likely to miss important passages because terms were distributed over several mini-documents , while if units are too large we tend to get spurious matches and the relevant-information is hard for the user to find . the problems with large document units can be alleviated by use of explicit or implicit proximity-search (and 7.2.2) , and the tradeoffs in resulting system-performance that we are hinting at are discussed in chapter 8 . the issue of index granularity , and in particular a need to simultaneously index documents at multiple levels of granularity , appears prominently in xml-retrieval , and is taken up again in chapter 10 . an ir-system should be designed to offer choices of granularity . for this choice to be made well , the person who is deploying the system must have a good understanding of the document collection , the users , and their likely information-needs and usage-patterns . for now , we will henceforth assume that a suitable size document unit has been chosen , together with an appropriate way of dividing or aggregating files , if needed .